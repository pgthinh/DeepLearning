 2024-12-02 at 09:00:06 | Training setting:
DotMap(mode='train', exp_name='exp', dataset='Clotho', text_encoder='bert', joint_embed=1024, wav=DotMap(sr=32000, window_size=1024, hop_length=320, mel_bins=64), bert_encoder=DotMap(type='bert-base-uncased', freeze=True), cnn_encoder=DotMap(model='ResNet38', pretrained=True, freeze=True), data=DotMap(batch_size=256, num_workers=8), training=DotMap(epsilon=0.03, m=0.95, margin=0.2, freeze=False, loss='ot', use_pot=False, reg=0, spec_augmentation=True, epochs=10, lr=5e-05, clip_grad=2, seed=1997, resume=False, l2_norm=True, dropout=0.2, use_cosine=False, noise_p=0), path=DotMap(vocabulary='data/{}/pickles/words_list.p', word2vec='pretrained_models/w2v_all_vocabulary.model', resume_model=''))
 2024-12-02 at 09:00:06 | Process on Tesla T4
 2024-12-02 at 09:05:43 | Training setting:
DotMap(mode='train', exp_name='exp', dataset='Clotho', text_encoder='bert', joint_embed=1024, wav=DotMap(sr=32000, window_size=1024, hop_length=320, mel_bins=64), bert_encoder=DotMap(type='bert-base-uncased', freeze=True), cnn_encoder=DotMap(model='ResNet38', pretrained=True, freeze=True), data=DotMap(batch_size=256, num_workers=8), training=DotMap(epsilon=0.03, m=0.95, margin=0.2, freeze=False, loss='ot', use_pot=False, reg=0, spec_augmentation=True, epochs=10, lr=5e-05, clip_grad=2, seed=1997, resume=False, l2_norm=True, dropout=0.2, use_cosine=False, noise_p=0), path=DotMap(vocabulary='data/{}/pickles/words_list.p', word2vec='pretrained_models/w2v_all_vocabulary.model', resume_model=''))
 2024-12-02 at 09:05:43 | Process on Tesla T4
 2024-12-02 at 09:05:51 | Size of training set: 19195, size of batches: 74
 2024-12-02 at 09:05:51 | Size of validation set: 5225, size of batches: 21
 2024-12-02 at 09:05:51 | Size of test set: 5225, size of batches: 21
 2024-12-02 at 09:05:51 | Training for epoch [1]
 2024-12-02 at 09:11:57 | Training setting:
DotMap(mode='train', exp_name='exp', dataset='Clotho', text_encoder='bert', joint_embed=1024, wav=DotMap(sr=32000, window_size=1024, hop_length=320, mel_bins=64), bert_encoder=DotMap(type='bert-base-uncased', freeze=True), cnn_encoder=DotMap(model='ResNet38', pretrained=True, freeze=True), data=DotMap(batch_size=64, num_workers=4), training=DotMap(epsilon=0.03, m=0.95, margin=0.2, freeze=False, loss='ot', use_pot=False, reg=0, spec_augmentation=True, epochs=10, lr=5e-05, clip_grad=2, seed=1997, resume=False, l2_norm=True, dropout=0.2, use_cosine=False, noise_p=0), path=DotMap(vocabulary='data/{}/pickles/words_list.p', word2vec='pretrained_models/w2v_all_vocabulary.model', resume_model=''))
 2024-12-02 at 09:11:57 | Process on Tesla T4
 2024-12-02 at 09:12:05 | Size of training set: 19195, size of batches: 299
 2024-12-02 at 09:12:05 | Size of validation set: 5225, size of batches: 82
 2024-12-02 at 09:12:05 | Size of test set: 5225, size of batches: 82
 2024-12-02 at 09:12:05 | Training for epoch [1]
 2024-12-02 at 09:13:34 | Training setting:
DotMap(mode='train', exp_name='exp', dataset='Clotho', text_encoder='bert', joint_embed=1024, wav=DotMap(sr=32000, window_size=1024, hop_length=320, mel_bins=64), bert_encoder=DotMap(type='bert-base-uncased', freeze=True), cnn_encoder=DotMap(model='ResNet38', pretrained=True, freeze=True), data=DotMap(batch_size=32, num_workers=4), training=DotMap(epsilon=0.03, m=0.95, margin=0.2, freeze=False, loss='ot', use_pot=False, reg=0, spec_augmentation=True, epochs=10, lr=5e-05, clip_grad=2, seed=1997, resume=False, l2_norm=True, dropout=0.2, use_cosine=False, noise_p=0), path=DotMap(vocabulary='data/{}/pickles/words_list.p', word2vec='pretrained_models/w2v_all_vocabulary.model', resume_model=''))
 2024-12-02 at 09:13:34 | Process on Tesla T4
 2024-12-02 at 09:13:41 | Size of training set: 19195, size of batches: 599
 2024-12-02 at 09:13:41 | Size of validation set: 5225, size of batches: 164
 2024-12-02 at 09:13:41 | Size of test set: 5225, size of batches: 164
 2024-12-02 at 09:13:41 | Training for epoch [1]
 2024-12-02 at 09:16:26 | Training setting:
DotMap(mode='train', exp_name='exp', dataset='Clotho', text_encoder='bert', joint_embed=1024, wav=DotMap(sr=32000, window_size=1024, hop_length=320, mel_bins=64), bert_encoder=DotMap(type='bert-base-uncased', freeze=True), cnn_encoder=DotMap(model='ResNet38', pretrained=True, freeze=True), data=DotMap(batch_size=16, num_workers=4), training=DotMap(epsilon=0.03, m=0.95, margin=0.2, freeze=False, loss='ot', use_pot=False, reg=0, spec_augmentation=True, epochs=10, lr=5e-05, clip_grad=2, seed=1997, resume=False, l2_norm=True, dropout=0.2, use_cosine=False, noise_p=0), path=DotMap(vocabulary='data/{}/pickles/words_list.p', word2vec='pretrained_models/w2v_all_vocabulary.model', resume_model=''))
 2024-12-02 at 09:16:26 | Process on Tesla T4
 2024-12-02 at 09:16:31 | Size of training set: 19195, size of batches: 1199
 2024-12-02 at 09:16:31 | Size of validation set: 5225, size of batches: 327
 2024-12-02 at 09:16:31 | Size of test set: 5225, size of batches: 327
 2024-12-02 at 09:16:31 | Training for epoch [1]
 2024-12-02 at 09:18:09 | Training setting:
DotMap(mode='train', exp_name='exp', dataset='Clotho', text_encoder='bert', joint_embed=1024, wav=DotMap(sr=32000, window_size=1024, hop_length=320, mel_bins=64), bert_encoder=DotMap(type='bert-base-uncased', freeze=True), cnn_encoder=DotMap(model='ResNet38', pretrained=True, freeze=True), data=DotMap(batch_size=8, num_workers=4), training=DotMap(epsilon=0.03, m=0.95, margin=0.2, freeze=False, loss='ot', use_pot=False, reg=0, spec_augmentation=True, epochs=10, lr=5e-05, clip_grad=2, seed=1997, resume=False, l2_norm=True, dropout=0.2, use_cosine=False, noise_p=0), path=DotMap(vocabulary='data/{}/pickles/words_list.p', word2vec='pretrained_models/w2v_all_vocabulary.model', resume_model=''))
 2024-12-02 at 09:18:09 | Process on Tesla T4
 2024-12-02 at 09:18:14 | Size of training set: 19195, size of batches: 2399
 2024-12-02 at 09:18:14 | Size of validation set: 5225, size of batches: 654
 2024-12-02 at 09:18:14 | Size of test set: 5225, size of batches: 654
 2024-12-02 at 09:18:14 | Training for epoch [1]
 2024-12-02 at 09:29:41 | Training setting:
DotMap(mode='train', exp_name='exp', dataset='Clotho', text_encoder='bert', joint_embed=1024, wav=DotMap(sr=32000, window_size=1024, hop_length=320, mel_bins=64), bert_encoder=DotMap(type='bert-base-uncased', freeze=True), cnn_encoder=DotMap(model='ResNet38', pretrained=True, freeze=True), data=DotMap(batch_size=8, num_workers=4), training=DotMap(epsilon=0.03, m=0.95, margin=0.2, freeze=False, loss='ot', use_pot=False, reg=0, spec_augmentation=True, epochs=10, lr=5e-05, clip_grad=2, seed=1997, resume=False, l2_norm=True, dropout=0.2, use_cosine=False, noise_p=0), path=DotMap(vocabulary='data/{}/pickles/words_list.p', word2vec='pretrained_models/w2v_all_vocabulary.model', resume_model=''))
 2024-12-02 at 09:29:41 | Process on Tesla T4
 2024-12-02 at 09:29:46 | Size of training set: 19195, size of batches: 2399
 2024-12-02 at 09:29:46 | Size of validation set: 5225, size of batches: 654
 2024-12-02 at 09:29:46 | Size of test set: 5225, size of batches: 654
 2024-12-02 at 09:29:46 | Training for epoch [1]
